{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-7111e3ae-b60e-4569-b774-a13ef1b95f77",
    "deepnote_cell_type": "markdown",
    "id": "XUZ1dFPHzAHl"
   },
   "source": [
    "<h1><center>Laboratorio 8: 쯉uperh칠roe o Villano? 游붲</center></h1>\n",
    "\n",
    "<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-988ebcea-7685-4ad4-968d-5530ff0099a7",
    "deepnote_cell_type": "markdown",
    "id": "UD8X1uhGzAHq"
   },
   "source": [
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesor: Pablo Badilla\n",
    "- Auxiliar: Ignacio Meza D.\n",
    "- Ayudante: Constanza Pe침a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-038ebafa-6641-4c2a-b2e8-62ad2018b88e",
    "deepnote_cell_type": "markdown",
    "id": "tXflExjqzAHr"
   },
   "source": [
    "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados\n",
    "\n",
    "- Nombre de alumno 1: Waldo Campos Maldonado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-913d0cc4-e146-4ff9-a0e3-26a20c808d7c",
    "deepnote_cell_type": "markdown",
    "id": "AD-V0bbZzAHr"
   },
   "source": [
    "### **Link de repositorio de GitHub:** `https://github.com/WaldoCampos/mds7202`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-e5841000-37dc-494f-a9b8-3c30765c243a",
    "deepnote_cell_type": "markdown",
    "id": "EcnsiQMkzAHr"
   },
   "source": [
    "### Indice \n",
    "\n",
    "1. [Temas a tratar](#Temas-a-tratar:)\n",
    "3. [Descripcci칩n del laboratorio](#Descripci칩n-del-laboratorio.)\n",
    "4. [Desarrollo](#Desarrollo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-64f7c2d0-4287-4f3a-9b4b-2c5b829f606c",
    "deepnote_cell_type": "markdown",
    "id": "6uBLPj1PzAHs"
   },
   "source": [
    "# Temas a tratar\n",
    "\n",
    "- Exploraci칩n del dataset y los resultados a trav칠s de visualizaciones interactivas usando `plotly`.\n",
    "- Introducci칩n a procesamiento del lenguaje natural.\n",
    "- Clasificaci칩n en `scikit-learn`\n",
    "- Uso de pipelines.\n",
    "\n",
    "## Reglas:\n",
    "\n",
    "- Fecha de entrega: 26/11/2021\n",
    "- **Grupos de 2 personas**\n",
    "- **Ausentes** deber치n realizar la actividad solos. \n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
    "- Prohibidas las copias. \n",
    "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
    "\n",
    "### Objetivos principales del laboratorio\n",
    "\n",
    "- Aplicar las ventajas que nos ofrece crear un pipeline.\n",
    "- Obtener caracteristicas desde texto.\n",
    "- Visualizar el funcionamiento de clasificadores.\n",
    "- Realizar una GridSearch sobre un conjunto de clasificadores.\n",
    "\n",
    "El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-b8353b3b-8f85-4aa6-9379-96902d3d0bf3",
    "deepnote_cell_type": "markdown",
    "id": "MhISwri4zAHy"
   },
   "source": [
    "#Importamos librerias utiles 游땾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T00:08:16.884674Z",
     "start_time": "2021-03-29T00:08:16.349846Z"
    },
    "cell_id": "00007-e696189c-3187-4899-bf04-8034b0e8a595",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     21.199996948242188
    ],
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 9106,
     "status": "ok",
     "timestamp": 1625497725070,
     "user": {
      "displayName": "IGNACIO ALEJANDRO MEZA",
      "photoUrl": "",
      "userId": "17011121633069169364"
     },
     "user_tz": 240
    },
    "execution_millis": 36497,
    "execution_start": 1637348694866,
    "id": "uyc33dKdzAHy",
    "outputId": "14d5da48-5dae-4ce4-a8ba-b826ea91a126",
    "source_hash": "7ce9748b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (5.4.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from plotly) (1.15.0)\n",
      "Requirement already satisfied: umap-learn in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from umap-learn) (1.20.3)\n",
      "Requirement already satisfied: numba>=0.49 in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from umap-learn) (0.54.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from umap-learn) (1.0.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from umap-learn) (0.5.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from umap-learn) (4.62.3)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from umap-learn) (1.7.1)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from numba>=0.49->umap-learn) (0.37.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from numba>=0.49->umap-learn) (58.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from scikit-learn>=0.22->umap-learn) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from tqdm->umap-learn) (0.4.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Waldo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Waldo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Librer칤a Core del lab.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Pre-procesamiento\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Clasifaci칩n\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Metricas de evaluaci칩n\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Librer칤a para plotear\n",
    "!pip install --upgrade plotly\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Proyecciones en baja dimensionalidad: UMAP\n",
    "!pip install umap-learn\n",
    "\n",
    "# Librer칤a para NLP\n",
    "!pip install nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize  \n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-9c535dd9-01e0-4804-a325-7b5d36a20a32",
    "deepnote_cell_type": "markdown",
    "id": "xpOTbQcxbSiy"
   },
   "source": [
    "# 1. 쯈uien es Bat Cow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-43ac5618-611f-4712-aec7-faaa53d72d08",
    "deepnote_cell_type": "markdown",
    "id": "3Q93vbNS25bM"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://i.imgur.com/D9f1RHy.jpg\" width=\"350\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-632e9494-ce9c-4d54-8e57-e700baed4302",
    "deepnote_cell_type": "markdown",
    "id": "jnmZfFpxTTYX"
   },
   "source": [
    "En vez de estar desarrollando las evaluaciones correspondientes a su curso, su profesor de catedra y su auxiliar discuten acerca la alineaci칩n (h칠roe o villano) del personaje de ficci칩n Bat-Cow. \n",
    "\n",
    "El cuerpo docente, no logra ponerse de acuerdo si el personaje es bueno, neutral o malo: el auxiliar plantea que Bat-cow posee una siniestra mirada, intrigante pero com칰n caracter칤stica de los personajes malvados. \n",
    "Por otra parte, extendiendo las ideas de Rousseau, el profesor plantea que tal como los humanos no nacen malos, no existe motivo por el cual una vaca con superpoderes deba serlo.\n",
    "\n",
    "Sin embargo, ambos concuerdan que es dif칤cil estimar la alineaci칩n solo usando los atributos f칤sicos, por lo que creen el an치lisis debe ser complementado a칰n m치s antes de comunicarle los resultados a su estudiantado. Buscando m치s informaci칩n, ambos sujetos se percatan de la existencia de un excelente antecedente para estimar la alineaci칩n: la historia personal de cada superh칠roe o villano.\n",
    "\n",
    "Es por esto le solicitan que construya y optimice un clasificador basado en texto el cual analice la alineaci칩n de cada personaje basado en su historia personal.\n",
    "\n",
    "Para este laboratorio deben trabajar con los datos `df_comics.csv` y `comics_no_label.csv` subidos a u-cursos. El primero es un conjunto de datos que les servir치 para entrenar un modelo de clasificaci칩n, mientras que el segundo es un dataset con personajes de ficci칩n no etiquetados a predecir (s칤, aqu칤 est치 la misteriosa Batcow).\n",
    "\n",
    "Para comenzar cargue los dataset se침alados y visualice a trav칠s de un head los atributos que poseen cada uno de los dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00011-9a36781e-c26a-46de-b4bf-a5448a347cab",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1625497735673,
     "user": {
      "displayName": "IGNACIO ALEJANDRO MEZA",
      "photoUrl": "",
      "userId": "17011121633069169364"
     },
     "user_tz": 240
    },
    "execution_millis": 27,
    "execution_start": 1637348657022,
    "id": "Jqq-s010Iwl1",
    "outputId": "bc29f770-d066-4443-8cee-00e3db46c629",
    "source_hash": "c60dc4a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignorando conexi칩n drive-colab\n"
     ]
    }
   ],
   "source": [
    "# Si usted est치 utilizando Colabolatory le puede ser 칰til este c칩digo para cargar los archivos.\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    path = 'Direcci칩n donde tiene los archivos en el Drive'\n",
    "except: \n",
    "    print('Ignorando conexi칩n drive-colab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00012-8b0c36c2-aeaa-4ba1-9611-45f0599aa584",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1625499009249,
     "user": {
      "displayName": "IGNACIO ALEJANDRO MEZA",
      "photoUrl": "",
      "userId": "17011121633069169364"
     },
     "user_tz": 240
    },
    "execution_millis": 325,
    "execution_start": 1637348732856,
    "id": "bED3w3tDbSCf",
    "source_hash": "443d6e8"
   },
   "outputs": [],
   "source": [
    "df_comics = pd.read_csv('df_comics.csv')\n",
    "df_comics_no_label = pd.read_csv('comics_no_label.csv')\n",
    "df_comics = df_comics.dropna(subset=['history_text']) # eliminar ejemplos sin historia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00013-2cd3a433-4f43-4a9e-92f5-caf54a662db2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 654,
    "execution_start": 1637348731943,
    "scrolled": false,
    "source_hash": "b986316d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>real_name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>overall_score</th>\n",
       "      <th>history_text</th>\n",
       "      <th>powers_text</th>\n",
       "      <th>intelligence_score</th>\n",
       "      <th>strength_score</th>\n",
       "      <th>speed_score</th>\n",
       "      <th>...</th>\n",
       "      <th>has_flight</th>\n",
       "      <th>has_accelerated_healing</th>\n",
       "      <th>has_weapons_master</th>\n",
       "      <th>has_intelligence</th>\n",
       "      <th>has_reflexes</th>\n",
       "      <th>has_super_speed</th>\n",
       "      <th>has_durability</th>\n",
       "      <th>has_stamina</th>\n",
       "      <th>has_agility</th>\n",
       "      <th>has_super_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3-D Man</td>\n",
       "      <td>Delroy Garrett, Jr.</td>\n",
       "      <td>Delroy Garrett, Jr.</td>\n",
       "      <td>6</td>\n",
       "      <td>Delroy Garrett, Jr. grew up to become a track ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A-Bomb</td>\n",
       "      <td>Richard Milhouse Jones</td>\n",
       "      <td>Richard Milhouse Jones</td>\n",
       "      <td>20</td>\n",
       "      <td>Richard \"Rick\" Jones was orphaned at a young ...</td>\n",
       "      <td>On rare occasions, and through unusual circu...</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aa</td>\n",
       "      <td>Aa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>Aa is one of the more passive members of the P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Aaron Cash</td>\n",
       "      <td>Aaron Cash</td>\n",
       "      <td>Aaron Cash</td>\n",
       "      <td>5</td>\n",
       "      <td>Aaron Cash is the head of security at Arkham A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Aayla Secura</td>\n",
       "      <td>Aayla Secura</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>ayla Secura was a Rutian Twi'lek Jedi Knight (...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows 칑 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          name               real_name               full_name  \\\n",
       "0           0       3-D Man     Delroy Garrett, Jr.     Delroy Garrett, Jr.   \n",
       "1           2        A-Bomb  Richard Milhouse Jones  Richard Milhouse Jones   \n",
       "2           3            Aa                      Aa                     NaN   \n",
       "3           4    Aaron Cash              Aaron Cash              Aaron Cash   \n",
       "4           5  Aayla Secura            Aayla Secura                     NaN   \n",
       "\n",
       "  overall_score                                       history_text  \\\n",
       "0             6  Delroy Garrett, Jr. grew up to become a track ...   \n",
       "1            20   Richard \"Rick\" Jones was orphaned at a young ...   \n",
       "2            12  Aa is one of the more passive members of the P...   \n",
       "3             5  Aaron Cash is the head of security at Arkham A...   \n",
       "4             8  ayla Secura was a Rutian Twi'lek Jedi Knight (...   \n",
       "\n",
       "                                         powers_text  intelligence_score  \\\n",
       "0                                                NaN                  85   \n",
       "1    On rare occasions, and through unusual circu...                  80   \n",
       "2                                                NaN                  80   \n",
       "3                                                NaN                  80   \n",
       "4                                                NaN                  90   \n",
       "\n",
       "   strength_score  speed_score  ...  has_flight  has_accelerated_healing  \\\n",
       "0              30           60  ...         0.0                      0.0   \n",
       "1             100           80  ...         0.0                      1.0   \n",
       "2              50           55  ...         0.0                      0.0   \n",
       "3              10           25  ...         0.0                      0.0   \n",
       "4              40           45  ...         0.0                      1.0   \n",
       "\n",
       "   has_weapons_master has_intelligence has_reflexes has_super_speed  \\\n",
       "0                 0.0              0.0          0.0             1.0   \n",
       "1                 0.0              0.0          1.0             1.0   \n",
       "2                 0.0              0.0          0.0             0.0   \n",
       "3                 1.0              0.0          0.0             0.0   \n",
       "4                 0.0              0.0          0.0             0.0   \n",
       "\n",
       "  has_durability has_stamina has_agility has_super_strength  \n",
       "0            0.0         0.0         0.0                1.0  \n",
       "1            1.0         1.0         1.0                1.0  \n",
       "2            0.0         0.0         0.0                0.0  \n",
       "3            0.0         0.0         0.0                0.0  \n",
       "4            0.0         0.0         1.0                0.0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# queda a labor de su equipo hacer el an치lisis exploratorio\n",
    "df_comics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'name', 'real_name', 'full_name', 'overall_score',\n",
       "       'history_text', 'powers_text', 'intelligence_score', 'strength_score',\n",
       "       'speed_score', 'durability_score', 'power_score', 'combat_score',\n",
       "       'superpowers', 'alter_egos', 'aliases', 'place_of_birth',\n",
       "       'first_appearance', 'creator', 'alignment', 'occupation', 'base',\n",
       "       'teams', 'relatives', 'gender', 'type_race', 'height', 'weight',\n",
       "       'eye_color', 'hair_color', 'skin_color', 'img', 'has_electrokinesis',\n",
       "       'has_energy_constructs', 'has_mind_control_resistance',\n",
       "       'has_matter_manipulation', 'has_telepathy_resistance',\n",
       "       'has_mind_control', 'has_enhanced_hearing', 'has_dimensional_travel',\n",
       "       'has_element_control', 'has_size_changing', 'has_fire_resistance',\n",
       "       'has_fire_control', 'has_dexterity', 'has_reality_warping',\n",
       "       'has_illusions', 'has_energy_beams', 'has_peak_human_condition',\n",
       "       'has_shapeshifting', 'has_heat_resistance', 'has_jump',\n",
       "       'has_self-sustenance', 'has_energy_absorption', 'has_cold_resistance',\n",
       "       'has_magic', 'has_telekinesis', 'has_toxin_and_disease_resistance',\n",
       "       'has_telepathy', 'has_regeneration', 'has_immortality',\n",
       "       'has_teleportation', 'has_force_fields', 'has_energy_manipulation',\n",
       "       'has_endurance', 'has_longevity', 'has_weapon-based_powers',\n",
       "       'has_energy_blasts', 'has_enhanced_senses', 'has_invulnerability',\n",
       "       'has_stealth', 'has_marksmanship', 'has_flight',\n",
       "       'has_accelerated_healing', 'has_weapons_master', 'has_intelligence',\n",
       "       'has_reflexes', 'has_super_speed', 'has_durability', 'has_stamina',\n",
       "       'has_agility', 'has_super_strength'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comics.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-00e51eac-6169-4978-9714-ee8c7a8f55b8",
    "deepnote_cell_type": "markdown",
    "id": "i4tFPrFA4_O5"
   },
   "source": [
    "## 1.1 Obtenci칩n de Features y Bag of Words\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media0.giphy.com/media/eIUpSyzwGp0YhAMTKr/200.gif\" width=\"300\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00014-528c8f39-a27a-40e0-8de0-0cc7f362b4ae",
    "deepnote_cell_type": "markdown",
    "id": "f_4NF0_V5XZ-"
   },
   "source": [
    "Primero que todo, deben obtener un vector de caracter칤sticas del atributo `history_text`, utilizando `bag of words`. En este atributo se presenta una breve descripci칩n de la historia de cada uno de los personajes de ficci칩n presentes en el dataset. \n",
    "\n",
    "Pero... antes de empezar, 쯈ue es `bag of words`?...\n",
    "\n",
    "`bag of words` es un modelo de conteo utilizado en Procesamiento de Lenguaje Natural (NLP) que tiene como objetivo generar una representaci칩n vectorial (vector de caracter칤sticas en nuestro cas) para cada documento a trav칠s del conteo de las palabras que contienen. \n",
    "\n",
    "La siguiente figura muestra un ejemplo de `bag of words` en acci칩n:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://user.oc-static.com/upload/2020/10/23/16034397439042_surfin%20bird%20bow.png\" width=\"500\">\n",
    "</p>\n",
    "\n",
    "Como pueden ver, el modelo de `bag of words` no resulta tan complicado, 쯣ero c칩mo lo aplicamos en python?. \n",
    "\n",
    "Como podr치n darse cuenta del ejemplo anterior, para facilitar el conteo ser치 necesario transformar cada uno de los documentos en vectores, donde cada una de las posiciones posee un car치cter. Este proceso es conocido como **tokenizaci칩n** y lo podemos realizar de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00015-5924cc55-1587-4776-8c5e-cb400ddacaa3",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     40.399993896484375
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8,
    "execution_start": 1637346921830,
    "source_hash": "57e4888a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'teacher', 'rocks', 'like', 'a', 'good', 'rock', '&', 'roll'],\n",
       " ['the', 'rock', 'is', 'the', 'best', 'actor', 'in', 'the', 'world']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = ['The teacher rocks like a good rock & roll',\n",
    "             'the rock is the best actor in the world']\n",
    "\n",
    "\n",
    "docs_tokenizados = [word_tokenize(doc)  for doc in docs]\n",
    "docs_tokenizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-649b0384-cac3-4b79-93ff-75aac3b8c5df",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Podemos mejorar un poco m치s el proceso de tokenizaci칩n agregando \n",
    "\n",
    "- Stemming:  Definimos Stemming como un algoritmo basado en reglas que transforma las palabras a una forma general. Un ejemplo de stemming, es el siguiente:\n",
    "- Eliminaci칩n de Stopwords: Eliminaci칩n de palabras muy frecuentes que entorpecen la clasificaci칩n (por ejemplo, el, la los, la, etc...)\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://devopedia.org/images/article/218/8583.1569386710.png\" width=\"300\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00017-52acaa25-55d2-49ee-a6c8-49437b8d4523",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     59.600006103515625
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 36,
    "execution_start": 1637346924545,
    "source_hash": "d7f59237",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Waldo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['the', 'teacher', 'rock', 'like', 'good', 'rock', '&', 'roll'],\n",
       " ['the', 'rock', 'is', 'the', 'best', 'actor', 'in', 'the', 'world'],\n",
       " ['new', 'york', 'is', 'beauti', 'citi']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definimos algunas stopword que queremos que sean eliminadas\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('spanish')\n",
    "\n",
    "# Definimos un tokenizador con Stemming\n",
    "class StemmerTokenizer:\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        doc_tok = word_tokenize(doc)\n",
    "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
    "        return [self.ps.stem(t) for t in doc_tok]\n",
    "\n",
    "# Inicializamos tokenizador\n",
    "tokenizador = StemmerTokenizer()\n",
    "\n",
    "# Creamos algunos documentos\n",
    "docs = ['The teacher rocks like a good rock & roll',\n",
    "        'the rock is the best actor in the world',\n",
    "        'New York is a beautiful city']\n",
    "\n",
    "# Obtenemos el token del primer documento\n",
    "[tokenizador(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00018-03a0f079-19df-42cb-b3b9-863a9e2ecb7a",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     59.600006103515625
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1637346927213,
    "source_hash": "2503a9b4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'teacher', 'rocks', 'like', 'a', 'good', 'rock', '&', 'roll'],\n",
       " ['the', 'rock', 'is', 'the', 'best', 'actor', 'in', 'the', 'world'],\n",
       " ['New', 'York', 'is', 'a', 'beautiful', 'city']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparaci칩n con el caso anterior\n",
    "docs_tokenizados = [word_tokenize(doc) for doc in docs]\n",
    "docs_tokenizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00019-3f862033-7b4e-4623-b17f-545b988af69b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Al Estilo Scikit\n",
    "\n",
    "Scikit implementa `bag of words` a trav칠s de la clase `CountVectorizer()` la cual contiene muchas opciones para mejorar la tokenizaci칩n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00020-721a6ba0-0990-4436-9de5-4b4b53c5ff79",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     98,
     40.390625
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 152,
    "execution_start": 1637346927803,
    "source_hash": "2bc7124d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&amp;</th>\n",
       "      <th>actor</th>\n",
       "      <th>beauti</th>\n",
       "      <th>best</th>\n",
       "      <th>citi</th>\n",
       "      <th>good</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>like</th>\n",
       "      <th>new</th>\n",
       "      <th>rock</th>\n",
       "      <th>roll</th>\n",
       "      <th>teacher</th>\n",
       "      <th>the</th>\n",
       "      <th>world</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   &  actor  beauti  best  citi  good  in  is  like  new  rock  roll  teacher  \\\n",
       "0  1      0       0     0     0     1   0   0     1    0     2     1        1   \n",
       "1  0      1       0     1     0     0   1   1     0    0     1     0        0   \n",
       "2  0      0       1     0     1     0   0   1     0    1     0     0        0   \n",
       "\n",
       "   the  world  york  \n",
       "0    1      0     0  \n",
       "1    3      1     0  \n",
       "2    0      0     1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = CountVectorizer(tokenizer= StemmerTokenizer())\n",
    "df = bow.fit_transform(docs)\n",
    "\n",
    "pd.DataFrame(df.toarray(), columns=bow.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00021-b3e721d0-6b1f-4f91-aef8-7b04028286fe",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Una de las cosas m치s interesantes que provee son el use de n-gramas, los cuales, en palabras simples, son conjuntos de n-palabras que se concatenan entre si y que se consideran como tokens separados. \n",
    "\n",
    "Pensemos en `Nueva York`. Cuando se tokeniza Nueva York, se generan dos tokens independientes que a simple vista no tienen relaci칩n: `Nueva` `York`.\n",
    "Al usar n-gramas (en un rango min=1,max=2) , generamos tanto `Nueva` y `York` como tambi칠n `Nueva York` como un token independiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00022-a7abf0fb-cbf2-4745-a96a-dcad9d4bc00f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 241,
    "execution_start": 1637346930092,
    "source_hash": "6af25c7e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&amp;</th>\n",
       "      <th>&amp; roll</th>\n",
       "      <th>actor</th>\n",
       "      <th>actor in</th>\n",
       "      <th>beauti</th>\n",
       "      <th>beauti citi</th>\n",
       "      <th>best</th>\n",
       "      <th>best actor</th>\n",
       "      <th>citi</th>\n",
       "      <th>good</th>\n",
       "      <th>...</th>\n",
       "      <th>teacher</th>\n",
       "      <th>teacher rock</th>\n",
       "      <th>the</th>\n",
       "      <th>the best</th>\n",
       "      <th>the rock</th>\n",
       "      <th>the teacher</th>\n",
       "      <th>the world</th>\n",
       "      <th>world</th>\n",
       "      <th>york</th>\n",
       "      <th>york is</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows 칑 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   &  & roll  actor  actor in  beauti  beauti citi  best  best actor  citi  \\\n",
       "0  1       1      0         0       0            0     0           0     0   \n",
       "1  0       0      1         1       0            0     1           1     0   \n",
       "2  0       0      0         0       1            1     0           0     1   \n",
       "\n",
       "   good  ...  teacher  teacher rock  the  the best  the rock  the teacher  \\\n",
       "0     1  ...        1             1    1         0         0            1   \n",
       "1     0  ...        0             0    3         1         1            0   \n",
       "2     0  ...        0             0    0         0         0            0   \n",
       "\n",
       "   the world  world  york  york is  \n",
       "0          0      0     0        0  \n",
       "1          1      1     0        0  \n",
       "2          0      0     1        1  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = CountVectorizer(tokenizer= StemmerTokenizer(), ngram_range=(1,2))\n",
    "df = bow.fit_transform(docs)\n",
    "\n",
    "pd.DataFrame(df.toarray(), columns=bow.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00023-55bca23d-f3d4-4f39-ae9d-e8810b522c79",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "De los resultados, podemos ver que generamos vectores de conteo para cada una de las palabras que conforman el corpus.  Un punto extra que se agrega en esta obtenci칩n de frecuencias son los bigramas, que b치sicamente son el conjunto de palabras de tama침o de aparecen juntas en el texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00024-231f49a8-163f-457d-b933-9e5dad0e1e29",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Codificando los Super{heroes, villanos}  [0.5 Puntos]\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://c.tenor.com/LkQzw7k5DV4AAAAd/anime-hacking.gif\" width=\"300\">\n",
    "</p>\n",
    "\n",
    "Conociendo ahora que es el proceso de `bag of words`, aplique este modelo de obtenci칩n de caracteristicas de la siguiente forma en un pipeline:\n",
    "\n",
    "- Utilice el tokenizador entregado.\n",
    "- Obtenga caracteristicas de los unigramas y bigramas del texto (tal como el ejemplo).\n",
    "\n",
    "```python\n",
    "bog = CountVectorizer(tokenizer= StemmerTokenizer(),`\n",
    "                      ngram_range=(1,2) # Este punto es opcional y es para generar bigramas\n",
    "                      )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00025-145bb273-d73c-4ad1-8b84-46327add3a2e",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Finalmente, aplique `MinMaxScaler()` sobre `atributos_de_interes` y concatene el valor obtenido con el matriz de caracteristicas obtenidas con bag of words.\n",
    "\n",
    "```python\n",
    "atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n",
    "```\n",
    "\n",
    "No es necesario que obtenga un dataframe en concreto con las caracter칤sticas solicitadas. Se le recomienda generar un `ColumnTransformer()` para aplicar las transformaciones solicitadas en un pipeline.\n",
    "\n",
    "**To-Do:**\n",
    "- [ ] Obtener a traves de bag of words caracteristicas del resumen de historia de cada personaje.\n",
    "- [ ] Aplicar MinMaxScaler sobre los atributos de interes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00026-b13521a0-adf9-4c19-893e-ba6ed644ca12",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00026-898e0ee0-748d-4dac-bfc5-d72f4fe21827",
    "deepnote_cell_type": "code",
    "id": "ay080DunHcOS",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1285, 333920)\n",
      "(1285, 333920)\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Definimos un tokenizador con Stemming\n",
    "class StemmerTokenizer:\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        doc_tok = word_tokenize(doc)\n",
    "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
    "        return [self.ps.stem(t) for t in doc_tok]\n",
    "\n",
    "bow1 = CountVectorizer(tokenizer= StemmerTokenizer())\n",
    "df = bow.fit_transform(df_comics['history_text'])\n",
    "print(df.shape)\n",
    "bow2 = CountVectorizer(tokenizer= StemmerTokenizer(), ngram_range=(1,2))\n",
    "df = bow.fit_transform(df_comics['history_text'])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1285, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n",
    "\n",
    "df = MinMaxScaler().fit_transform(df_comics.loc[:, atributos_de_interes])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00029-0baf6cdb-9550-4717-87db-9f9900d5b276",
    "deepnote_cell_type": "markdown",
    "id": "stHncQ-A-j4I"
   },
   "source": [
    "## 1.2 Dise침o de Baseline y  Primer Entrenamiento  [1 Puntos]\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://pa1.narvii.com/6374/9eaec1b7bf9157334151452a669516f9a78b954c_hq.gif\" width=\"300\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00030-1452da19-1559-4b8b-8b73-a134157c0656",
    "deepnote_cell_type": "markdown",
    "id": "NeMiptpQ_EWb"
   },
   "source": [
    "Genere un Pipeline con las caracteristicas solicitadas en la secci칩n 1.1, un selector de mejores features `SelectPercentile` con m칠trica `f_classif` y percentile=90 y un clasificador `MultinomialNB()` por defecto.\n",
    "\n",
    "Luego, separe el conjunto de datos en un conjunto de entrenamiento y prueba, donde las etiquetas estar치 dado por el atributo `alignment`. \n",
    "\n",
    "Finalmente entrene el modelo y reporte el desempe침o con un `classification_report`.  Nos recomendar칤a predecir la alineaci칩n de BatCow con este clasificador?.\n",
    "\n",
    "**To-DO:**\n",
    "- [ ] Realizar un pipeline con las caracteristicas solicitadas en 1.1 y aplicar un clasificador  `MultinomialNB()`.\n",
    "- [ ] Entrenar el pipeline y comentar los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00029-34f1be30-f2df-45ac-aa14-8e05dc678be9",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "00031-92f07569-b6ee-48af-be9e-70cd05cb9e5e",
    "deepnote_cell_type": "code",
    "id": "_hHpPDooPafy"
   },
   "outputs": [],
   "source": [
    "bow = CountVectorizer(tokenizer= StemmerTokenizer(), ngram_range=(1,2))\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('bow', bow, 'history_text'),\n",
    "    ('minmaxscaler', MinMaxScaler(), atributos_de_interes)\n",
    "])\n",
    "\n",
    "bow_pipe = Pipeline([\n",
    "    ('preprocessing', ct),\n",
    "    ('feature selection', SelectPercentile(f_classif, percentile=90)),\n",
    "    ('naive bayes', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_comics.drop(columns=['alignment'])\n",
    "Y = df_comics['alignment']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, shuffle=True, stratify=Y, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = bow_pipe.fit(X_train, Y_train)\n",
    "y_pred_nb = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.62      0.09      0.16       142\n",
      "        Good       0.60      0.97      0.74       246\n",
      "     Neutral       0.00      0.00      0.00        37\n",
      "\n",
      "    accuracy                           0.59       425\n",
      "   macro avg       0.41      0.35      0.30       425\n",
      "weighted avg       0.55      0.59      0.48       425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Bad', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Neutral', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Bad', 'Bad', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Neutral',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Bad', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Bad', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Bad', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Bad', 'Good', 'Good', 'Good', 'Good', 'Good', 'Bad',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Bad', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Bad', 'Bad', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Bad', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Neutral', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Bad',\n",
       "       'Good', 'Good', 'Good', 'Bad', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Bad', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Bad',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Bad', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Bad', 'Good', 'Good', 'Bad',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Bad', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Bad', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good', 'Good',\n",
       "       'Good'], dtype='<U7')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un 59% de las predicciones son correctas, sin embargo el modelo est치 prediciendo que la gran mayor칤a de los datos tienen la etiqueta 'Good', estos datos corresponden al 57% del dataset, por lo que un modelo que solo predice 'Good' ya tendr칤a un 57% de accuracy. Esto significa que el modelo no es muy bueno identificando personajes de alinamiento malvado o neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00035-35040b90-b6b9-4e43-8eff-15b7fa897575",
    "deepnote_cell_type": "markdown",
    "id": "pfm7I2B7_rfB"
   },
   "source": [
    "## 1.3 Busqueda del Mejor Modelo con Grid Search [4 Puntos]\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/images/70fdfeea52a8e2e4505498c230a0d2f9/tenor.gif?itemid=5134219\" width=\"250\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00036-c58166cc-71f7-4fa3-94c8-c67d1145ccf1",
    "deepnote_cell_type": "markdown",
    "id": "14siiavzK67p"
   },
   "source": [
    "No conformes con el rendimiento obtenido en la secci칩n 1.2, el cuerpo docente les pide que realicen un **`HalvingGridSearchCV`** con diferentes par치metros para mejorar el rendimiento de la clasificaci칩n. Para esto, se le solicita que defina:\n",
    "\n",
    "- Dos clasificadores distintos en donde varie sus par치metros. Se le recomienda utilizar `LogisticRegression()` y `RandomForestClassifier()`.\n",
    "- Modificar `n-gram` range del `CountVectorizer` probando `(1,1), (1,2) y (1,3)`. \n",
    "- Selecci칩n de las mejores columnas para la clasificaci칩n con `SelectPercentile` en los percentiles `[20, 40, 60, 80]` (puede usar la m칠trica que usted quiera).\n",
    "\n",
    "A continuaci칩n, un ejemplo de parametros para GridSearch para una b칰squeda de 3 clasificadores distintos:\n",
    "\n",
    "```python\n",
    "params = [\n",
    "       # clasificador 1 + hiperpar치metros\n",
    "       {'clf': classificator1(),\n",
    "        'clf__penalty': ['ovr'],\n",
    "        'clf__multi_class': ['liblinear']},\n",
    "       # clasificador 1 + hiperpar치metros    \n",
    "       {'clf': classificator2(),\n",
    "        'clf__n_estimators': [200]},\n",
    "       # clasificador 1 + hiperpar치metros\n",
    "       {'clf': classificator3(),\n",
    "        ...\n",
    "       }\n",
    "       ]\n",
    "```\n",
    "\n",
    "**Nota 1**: Puede ver los par치metros modificables aplicando el m칠todo get_params() sobre su pipeline.\n",
    "\n",
    "**Nota 2**: Recuerde inicializar los clasificadores con un random state definido.\n",
    "\n",
    "**Nota 3**: Puede usar en `HalvingGridSearchCV` el par치metro `verbose=10` para ver que GridSearch le indique el estado de su ejecuci칩n.\n",
    "\n",
    "**Nota 3:** El GridSearch puede tomar tiempos de b칰squeda exorbitantes, por lo que se le recomienda no agrandar mucho el espacio de b칰squeda, dejar corriendo el c칩digo y tomarse un tecito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00032-3fea06e0-a390-4ae0-8036-f5fedb6d6baf",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('preprocessing',\n",
       "   ColumnTransformer(transformers=[('bow',\n",
       "                                    CountVectorizer(ngram_range=(1, 2),\n",
       "                                                    tokenizer=<__main__.StemmerTokenizer object at 0x000001C571AB06D0>),\n",
       "                                    'history_text'),\n",
       "                                   ('minmaxscaler', MinMaxScaler(),\n",
       "                                    ['intelligence_score', 'strength_score',\n",
       "                                     'speed_score', 'durability_score',\n",
       "                                     'power_score', 'combat_score'])])),\n",
       "  ('feature selection', SelectPercentile(percentile=90)),\n",
       "  ('naive bayes', MultinomialNB())],\n",
       " 'verbose': False,\n",
       " 'preprocessing': ColumnTransformer(transformers=[('bow',\n",
       "                                  CountVectorizer(ngram_range=(1, 2),\n",
       "                                                  tokenizer=<__main__.StemmerTokenizer object at 0x000001C571AB06D0>),\n",
       "                                  'history_text'),\n",
       "                                 ('minmaxscaler', MinMaxScaler(),\n",
       "                                  ['intelligence_score', 'strength_score',\n",
       "                                   'speed_score', 'durability_score',\n",
       "                                   'power_score', 'combat_score'])]),\n",
       " 'feature selection': SelectPercentile(percentile=90),\n",
       " 'naive bayes': MultinomialNB(),\n",
       " 'preprocessing__n_jobs': None,\n",
       " 'preprocessing__remainder': 'drop',\n",
       " 'preprocessing__sparse_threshold': 0.3,\n",
       " 'preprocessing__transformer_weights': None,\n",
       " 'preprocessing__transformers': [('bow',\n",
       "   CountVectorizer(ngram_range=(1, 2),\n",
       "                   tokenizer=<__main__.StemmerTokenizer object at 0x000001C571AB06D0>),\n",
       "   'history_text'),\n",
       "  ('minmaxscaler',\n",
       "   MinMaxScaler(),\n",
       "   ['intelligence_score',\n",
       "    'strength_score',\n",
       "    'speed_score',\n",
       "    'durability_score',\n",
       "    'power_score',\n",
       "    'combat_score'])],\n",
       " 'preprocessing__verbose': False,\n",
       " 'preprocessing__verbose_feature_names_out': True,\n",
       " 'preprocessing__bow': CountVectorizer(ngram_range=(1, 2),\n",
       "                 tokenizer=<__main__.StemmerTokenizer object at 0x000001C571AB06D0>),\n",
       " 'preprocessing__minmaxscaler': MinMaxScaler(),\n",
       " 'preprocessing__bow__analyzer': 'word',\n",
       " 'preprocessing__bow__binary': False,\n",
       " 'preprocessing__bow__decode_error': 'strict',\n",
       " 'preprocessing__bow__dtype': numpy.int64,\n",
       " 'preprocessing__bow__encoding': 'utf-8',\n",
       " 'preprocessing__bow__input': 'content',\n",
       " 'preprocessing__bow__lowercase': True,\n",
       " 'preprocessing__bow__max_df': 1.0,\n",
       " 'preprocessing__bow__max_features': None,\n",
       " 'preprocessing__bow__min_df': 1,\n",
       " 'preprocessing__bow__ngram_range': (1, 2),\n",
       " 'preprocessing__bow__preprocessor': None,\n",
       " 'preprocessing__bow__stop_words': None,\n",
       " 'preprocessing__bow__strip_accents': None,\n",
       " 'preprocessing__bow__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'preprocessing__bow__tokenizer': <__main__.StemmerTokenizer at 0x1c571ab06d0>,\n",
       " 'preprocessing__bow__vocabulary': None,\n",
       " 'preprocessing__minmaxscaler__clip': False,\n",
       " 'preprocessing__minmaxscaler__copy': True,\n",
       " 'preprocessing__minmaxscaler__feature_range': (0, 1),\n",
       " 'feature selection__percentile': 90,\n",
       " 'feature selection__score_func': <function sklearn.feature_selection._univariate_selection.f_classif(X, y)>,\n",
       " 'naive bayes__alpha': 1.0,\n",
       " 'naive bayes__class_prior': None,\n",
       " 'naive bayes__fit_prior': True}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "00037-8b06a200-cb7a-485a-b11b-31a3d0ee57f3",
    "deepnote_cell_type": "code",
    "id": "oNvHOHELUoIv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "bow_pipe = Pipeline([\n",
    "    ('preprocessing', ct),\n",
    "    ('feature selection', SelectPercentile()),\n",
    "    ('clf', None)\n",
    "])\n",
    "\n",
    "params = [\n",
    "       # logistic regression\n",
    "       {'preprocessing__bow__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "        'feature selection__percentile': [20, 40, 60 ,80],\n",
    "        'feature selection__score_func': [f_classif],\n",
    "        'clf': [LogisticRegression(random_state=420)],\n",
    "        'clf__C': [0.1, 1, 10]},\n",
    "       # random forest  \n",
    "       {'preprocessing__bow__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "        'feature selection__percentile': [20, 40, 60 ,80],\n",
    "        'feature selection__score_func': [f_classif],\n",
    "        'clf': [RandomForestClassifier(random_state=69)],\n",
    "        'clf__criterion': ['gini', 'entropy']}\n",
    "       ]\n",
    "\n",
    "search = HalvingGridSearchCV(bow_pipe, params, verbose=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 31\n",
      "max_resources_: 860\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 60\n",
      "n_resources: 31\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "[CV 1/5; 1/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 1/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.958, test=0.667) total time=   0.8s\n",
      "[CV 2/5; 1/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 1/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   0.4s\n",
      "[CV 3/5; 1/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 1/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.958, test=0.167) total time=   0.9s\n",
      "[CV 4/5; 1/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 1/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.958, test=0.667) total time=   1.0s\n",
      "[CV 5/5; 1/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 1/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.958, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 2/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 2/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.958, test=0.500) total time=   0.9s\n",
      "[CV 2/5; 2/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 2/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 3/5; 2/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 2/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.958, test=0.167) total time=   1.0s\n",
      "[CV 4/5; 2/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 2/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.6s\n",
      "[CV 5/5; 2/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 2/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "[CV 1/5; 3/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 3/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   1.3s\n",
      "[CV 2/5; 3/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 3/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.7s\n",
      "[CV 3/5; 3/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 3/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.958, test=0.167) total time=   1.2s\n",
      "[CV 4/5; 3/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 3/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.4s\n",
      "[CV 5/5; 3/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 3/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 4/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 4/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.958, test=0.833) total time=   0.7s\n",
      "[CV 2/5; 4/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.5s\n",
      "[CV 3/5; 4/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.958, test=0.167) total time=   0.9s\n",
      "[CV 4/5; 4/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 4/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.3s\n",
      "[CV 5/5; 4/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 4/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 5/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 5/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.1s\n",
      "[CV 2/5; 5/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 5/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.9s\n",
      "[CV 3/5; 5/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.4s\n",
      "[CV 4/5; 5/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 5/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.5s\n",
      "[CV 5/5; 5/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 5/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "[CV 1/5; 6/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 6/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.2s\n",
      "[CV 2/5; 6/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 6/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.4s\n",
      "[CV 3/5; 6/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 6/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   2.0s\n",
      "[CV 4/5; 6/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 6/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.6s\n",
      "[CV 5/5; 6/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 6/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.6s\n",
      "[CV 1/5; 7/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 7/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.958, test=0.833) total time=   0.9s\n",
      "[CV 2/5; 7/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 7/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   0.6s\n",
      "[CV 3/5; 7/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 7/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   1.1s\n",
      "[CV 4/5; 7/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 7/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.2s\n",
      "[CV 5/5; 7/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 7/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "[CV 1/5; 8/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 8/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.833) total time=   1.0s\n",
      "[CV 2/5; 8/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 8/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 3/5; 8/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 8/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.8s\n",
      "[CV 4/5; 8/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 8/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.9s\n",
      "[CV 5/5; 8/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 8/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.8s\n",
      "[CV 1/5; 9/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 9/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.5s\n",
      "[CV 2/5; 9/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 9/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.3s\n",
      "[CV 3/5; 9/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   2.7s\n",
      "[CV 4/5; 9/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 9/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.9s\n",
      "[CV 5/5; 9/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 9/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.6s\n",
      "[CV 1/5; 10/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 10/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.958, test=0.833) total time=   0.9s\n",
      "[CV 2/5; 10/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 10/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   0.6s\n",
      "[CV 3/5; 10/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 10/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   1.2s\n",
      "[CV 4/5; 10/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 10/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.1s\n",
      "[CV 5/5; 10/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 10/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 11/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 11/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.833) total time=   1.1s\n",
      "[CV 2/5; 11/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 11/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.333) total time=   0.8s\n",
      "[CV 3/5; 11/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 11/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.8s\n",
      "[CV 4/5; 11/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 11/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.4s\n",
      "[CV 5/5; 11/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 11/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.6s\n",
      "[CV 1/5; 12/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 12/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.2s\n",
      "[CV 2/5; 12/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 12/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.3s\n",
      "[CV 3/5; 12/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 12/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   2.2s\n",
      "[CV 4/5; 12/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 12/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   2.1s\n",
      "[CV 5/5; 12/60] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 12/60] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.9s\n",
      "[CV 1/5; 13/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 13/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.833) total time=   0.9s\n",
      "[CV 2/5; 13/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 13/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   0.5s\n",
      "[CV 3/5; 13/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 13/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.958, test=0.167) total time=   0.9s\n",
      "[CV 4/5; 13/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 13/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.0s\n",
      "[CV 5/5; 13/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 13/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   0.5s\n",
      "[CV 1/5; 14/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 14/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.833) total time=   0.9s\n",
      "[CV 2/5; 14/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 14/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.5s\n",
      "[CV 3/5; 14/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 14/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.958, test=0.167) total time=   1.1s\n",
      "[CV 4/5; 14/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 14/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   2.2s\n",
      "[CV 5/5; 14/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 14/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 15/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 15/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   1.2s\n",
      "[CV 2/5; 15/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 15/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 3/5; 15/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 15/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.958, test=0.167) total time=   1.1s\n",
      "[CV 4/5; 15/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 15/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.6s\n",
      "[CV 5/5; 15/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 15/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.6s\n",
      "[CV 1/5; 16/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 16/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.833) total time=   1.1s\n",
      "[CV 2/5; 16/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 16/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.7s\n",
      "[CV 3/5; 16/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 16/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   1.3s\n",
      "[CV 4/5; 16/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 16/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.2s\n",
      "[CV 5/5; 16/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 16/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "[CV 1/5; 17/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 17/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.833) total time=   1.2s\n",
      "[CV 2/5; 17/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 17/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.8s\n",
      "[CV 3/5; 17/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 17/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.333) total time=   1.4s\n",
      "[CV 4/5; 17/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 17/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.5s\n",
      "[CV 5/5; 17/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 17/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 18/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 18/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.4s\n",
      "[CV 2/5; 18/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 18/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 18/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 18/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   2.0s\n",
      "[CV 4/5; 18/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 18/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.7s\n",
      "[CV 5/5; 18/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 18/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.6s\n",
      "[CV 1/5; 19/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 19/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.4s\n",
      "[CV 2/5; 19/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 19/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   0.8s\n",
      "[CV 3/5; 19/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 19/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   1.1s\n",
      "[CV 4/5; 19/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 19/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.4s\n",
      "[CV 5/5; 19/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 19/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 20/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 20/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.833) total time=   1.0s\n",
      "[CV 2/5; 20/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 20/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.8s\n",
      "[CV 3/5; 20/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 20/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.333) total time=   1.5s\n",
      "[CV 4/5; 20/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 20/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.5s\n",
      "[CV 5/5; 20/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 20/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 21/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 21/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.833) total time=   1.3s\n",
      "[CV 2/5; 21/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 21/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.3s\n",
      "[CV 3/5; 21/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 21/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   2.5s\n",
      "[CV 4/5; 21/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 21/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   2.1s\n",
      "[CV 5/5; 21/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 21/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.7s\n",
      "[CV 1/5; 22/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 22/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   0.9s\n",
      "[CV 2/5; 22/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 22/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   0.7s\n",
      "[CV 3/5; 22/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 22/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   1.3s\n",
      "[CV 4/5; 22/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 22/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.3s\n",
      "[CV 5/5; 22/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 22/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "[CV 1/5; 23/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 23/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.833) total time=   1.2s\n",
      "[CV 2/5; 23/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 23/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.333) total time=   1.0s\n",
      "[CV 3/5; 23/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 23/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.333) total time=   1.7s\n",
      "[CV 4/5; 23/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 23/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.6s\n",
      "[CV 5/5; 23/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 23/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "[CV 1/5; 24/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 24/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.833) total time=   1.4s\n",
      "[CV 2/5; 24/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 24/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.3s\n",
      "[CV 3/5; 24/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 24/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   3.1s\n",
      "[CV 4/5; 24/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 24/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.8s\n",
      "[CV 5/5; 24/60] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 24/60] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.6s\n",
      "[CV 1/5; 25/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 25/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.833) total time=   0.6s\n",
      "[CV 2/5; 25/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 25/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 3/5; 25/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 25/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   0.8s\n",
      "[CV 4/5; 25/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 25/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.5s\n",
      "[CV 5/5; 25/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 25/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   0.3s\n",
      "[CV 1/5; 26/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 26/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.833) total time=   0.8s\n",
      "[CV 2/5; 26/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 26/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.7s\n",
      "[CV 3/5; 26/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 26/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.333) total time=   0.9s\n",
      "[CV 4/5; 26/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 26/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.1s\n",
      "[CV 5/5; 26/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 26/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 27/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 27/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.9s\n",
      "[CV 2/5; 27/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 27/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.5s\n",
      "[CV 3/5; 27/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 27/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.333) total time=   1.0s\n",
      "[CV 4/5; 27/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 27/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.4s\n",
      "[CV 5/5; 27/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 27/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 28/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 28/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   0.7s\n",
      "[CV 2/5; 28/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 28/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.5s\n",
      "[CV 3/5; 28/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 28/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   1.2s\n",
      "[CV 4/5; 28/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 28/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.0s\n",
      "[CV 5/5; 28/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 28/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 29/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 29/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.833) total time=   1.2s\n",
      "[CV 2/5; 29/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 29/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.8s\n",
      "[CV 3/5; 29/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 29/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.333) total time=   1.4s\n",
      "[CV 4/5; 29/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 29/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.4s\n",
      "[CV 5/5; 29/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 29/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.6s\n",
      "[CV 1/5; 30/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 30/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.0s\n",
      "[CV 2/5; 30/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 30/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.0s\n",
      "[CV 3/5; 30/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 30/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.7s\n",
      "[CV 4/5; 30/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 30/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.8s\n",
      "[CV 5/5; 30/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 30/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   1.1s\n",
      "[CV 1/5; 31/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 31/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.9s\n",
      "[CV 2/5; 31/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 31/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   1.5s\n",
      "[CV 3/5; 31/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 31/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   1.5s\n",
      "[CV 4/5; 31/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 31/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.1s\n",
      "[CV 5/5; 31/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 31/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 32/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 32/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.833) total time=   0.8s\n",
      "[CV 2/5; 32/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 32/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.7s\n",
      "[CV 3/5; 32/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 32/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.333) total time=   1.9s\n",
      "[CV 4/5; 32/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 32/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.7s\n",
      "[CV 5/5; 32/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 32/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "[CV 1/5; 33/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 33/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.833) total time=   1.2s\n",
      "[CV 2/5; 33/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 33/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.4s\n",
      "[CV 3/5; 33/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 33/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   2.4s\n",
      "[CV 4/5; 33/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 33/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   2.0s\n",
      "[CV 5/5; 33/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 33/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.6s\n",
      "[CV 1/5; 34/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 34/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   0.8s\n",
      "[CV 2/5; 34/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 34/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   0.8s\n",
      "[CV 3/5; 34/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 34/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   1.1s\n",
      "[CV 4/5; 34/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 34/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.3s\n",
      "[CV 5/5; 34/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 34/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.6s\n",
      "[CV 1/5; 35/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 35/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.833) total time=   1.3s\n",
      "[CV 2/5; 35/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 35/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.333) total time=   1.1s\n",
      "[CV 3/5; 35/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 35/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.333) total time=   1.9s\n",
      "[CV 4/5; 35/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 35/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.8s\n",
      "[CV 5/5; 35/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 35/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "[CV 1/5; 36/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 36/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.833) total time=   1.4s\n",
      "[CV 2/5; 36/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 36/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.4s\n",
      "[CV 3/5; 36/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 36/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.333) total time=   2.7s\n",
      "[CV 4/5; 36/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 36/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   2.4s\n",
      "[CV 5/5; 36/60] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 36/60] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.8s\n",
      "[CV 1/5; 37/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 37/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.2s\n",
      "[CV 2/5; 37/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 37/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.9s\n",
      "[CV 3/5; 37/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 37/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   1.6s\n",
      "[CV 4/5; 37/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 37/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.8s\n",
      "[CV 5/5; 37/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 37/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.6s\n",
      "[CV 1/5; 38/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 38/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   1.8s\n",
      "[CV 2/5; 38/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 38/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.9s\n",
      "[CV 3/5; 38/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 38/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 4/5; 38/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 38/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.6s\n",
      "[CV 5/5; 38/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 38/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "[CV 1/5; 39/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 39/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   1.5s\n",
      "[CV 2/5; 39/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 39/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.3s\n",
      "[CV 3/5; 39/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 39/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.4s\n",
      "[CV 4/5; 39/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 39/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.4s\n",
      "[CV 5/5; 39/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 39/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.7s\n",
      "[CV 1/5; 40/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 40/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.0s\n",
      "[CV 2/5; 40/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 40/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 3/5; 40/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 40/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 4/5; 40/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 40/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.1s\n",
      "[CV 5/5; 40/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 40/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 41/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 41/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   0.9s\n",
      "[CV 2/5; 41/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 41/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.7s\n",
      "[CV 3/5; 41/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 41/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 4/5; 41/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 41/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.4s\n",
      "[CV 5/5; 41/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 41/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.6s\n",
      "[CV 1/5; 42/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 42/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   0.9s\n",
      "[CV 2/5; 42/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 42/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.8s\n",
      "[CV 3/5; 42/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 42/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 4/5; 42/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 42/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.6s\n",
      "[CV 5/5; 42/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 42/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.6s\n",
      "[CV 1/5; 43/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 43/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   0.9s\n",
      "[CV 2/5; 43/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 43/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   0.8s\n",
      "[CV 3/5; 43/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 43/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.0s\n",
      "[CV 4/5; 43/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 43/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.2s\n",
      "[CV 5/5; 43/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 43/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.7s\n",
      "[CV 1/5; 44/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 44/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   0.9s\n",
      "[CV 2/5; 44/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 44/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.7s\n",
      "[CV 3/5; 44/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 44/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 4/5; 44/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 44/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.4s\n",
      "[CV 5/5; 44/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 44/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "[CV 1/5; 45/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 45/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   1.0s\n",
      "[CV 2/5; 45/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 45/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.8s\n",
      "[CV 3/5; 45/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 45/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 4/5; 45/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 45/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.6s\n",
      "[CV 5/5; 45/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 45/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.6s\n",
      "[CV 1/5; 46/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 46/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   0.9s\n",
      "[CV 2/5; 46/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 46/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 3/5; 46/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 46/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 4/5; 46/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 46/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.4s\n",
      "[CV 5/5; 46/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 46/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 47/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 47/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.1s\n",
      "[CV 2/5; 47/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 47/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.8s\n",
      "[CV 3/5; 47/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 47/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 4/5; 47/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 47/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.5s\n",
      "[CV 5/5; 47/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 47/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 48/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 48/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.1s\n",
      "[CV 2/5; 48/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 48/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.7s\n",
      "[CV 3/5; 48/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 48/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 4/5; 48/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 48/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.6s\n",
      "[CV 5/5; 48/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 48/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "[CV 1/5; 49/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 49/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   0.8s\n",
      "[CV 2/5; 49/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 49/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.6s\n",
      "[CV 3/5; 49/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 49/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   1.0s\n",
      "[CV 4/5; 49/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 49/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.2s\n",
      "[CV 5/5; 49/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 49/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 50/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 50/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.1s\n",
      "[CV 2/5; 50/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 50/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 3/5; 50/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 50/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 4/5; 50/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 50/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.4s\n",
      "[CV 5/5; 50/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 50/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "[CV 1/5; 51/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 51/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.9s\n",
      "[CV 2/5; 51/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 51/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 3/5; 51/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 51/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 4/5; 51/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 51/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.2s\n",
      "[CV 5/5; 51/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 51/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.9s\n",
      "[CV 1/5; 52/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 52/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.2s\n",
      "[CV 2/5; 52/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 52/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.7s\n",
      "[CV 3/5; 52/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 52/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 4/5; 52/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 52/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.4s\n",
      "[CV 5/5; 52/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 52/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "[CV 1/5; 53/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 53/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   0.9s\n",
      "[CV 2/5; 53/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 53/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 3/5; 53/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 53/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.4s\n",
      "[CV 4/5; 53/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 53/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.9s\n",
      "[CV 5/5; 53/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 53/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.4s\n",
      "[CV 1/5; 54/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 54/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.0s\n",
      "[CV 2/5; 54/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 54/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.7s\n",
      "[CV 3/5; 54/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 54/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 4/5; 54/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 54/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.6s\n",
      "[CV 5/5; 54/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 54/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.7s\n",
      "[CV 1/5; 55/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 55/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   1.0s\n",
      "[CV 2/5; 55/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 55/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   0.6s\n",
      "[CV 3/5; 55/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 55/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 4/5; 55/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 55/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.4s\n",
      "[CV 5/5; 55/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 55/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "[CV 1/5; 56/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 56/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   0.9s\n",
      "[CV 2/5; 56/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 56/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.7s\n",
      "[CV 3/5; 56/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 56/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 4/5; 56/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 56/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.3s\n",
      "[CV 5/5; 56/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 56/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "[CV 1/5; 57/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 57/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   1.1s\n",
      "[CV 2/5; 57/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 57/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.0s\n",
      "[CV 3/5; 57/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 57/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.3s\n",
      "[CV 4/5; 57/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 57/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.7s\n",
      "[CV 5/5; 57/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 57/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.7s\n",
      "[CV 1/5; 58/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 58/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   0.9s\n",
      "[CV 2/5; 58/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 58/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 3/5; 58/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 58/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.0s\n",
      "[CV 4/5; 58/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 58/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.2s\n",
      "[CV 5/5; 58/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 58/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "[CV 1/5; 59/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 59/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.3s\n",
      "[CV 2/5; 59/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 59/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.8s\n",
      "[CV 3/5; 59/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 59/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 4/5; 59/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 59/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   1.2s\n",
      "[CV 5/5; 59/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 59/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.6s\n",
      "[CV 1/5; 60/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 60/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.833) total time=   1.0s\n",
      "[CV 2/5; 60/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 60/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.8s\n",
      "[CV 3/5; 60/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 60/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 4/5; 60/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 60/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.667) total time=   1.4s\n",
      "[CV 5/5; 60/60] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 60/60] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.5s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 20\n",
      "n_resources: 93\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5; 1/20] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/20] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.611) total time=   3.3s\n",
      "[CV 2/5; 1/20] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 1/20] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   3.0s\n",
      "[CV 3/5; 1/20] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 1/20] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.722) total time=   3.6s\n",
      "[CV 4/5; 1/20] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/20] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   3.3s\n",
      "[CV 5/5; 1/20] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 1/20] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   3.6s\n",
      "[CV 1/5; 2/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   1.7s\n",
      "[CV 2/5; 2/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 2/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   2.3s\n",
      "[CV 3/5; 2/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 2/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   2.2s\n",
      "[CV 4/5; 2/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 2/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   1.8s\n",
      "[CV 5/5; 2/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 2/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.611) total time=   2.3s\n",
      "[CV 1/5; 3/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.611) total time=   2.8s\n",
      "[CV 2/5; 3/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 3/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   2.7s\n",
      "[CV 3/5; 3/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 3/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   3.0s\n",
      "[CV 4/5; 3/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.556) total time=   3.0s\n",
      "[CV 5/5; 3/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 3/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.556) total time=   3.1s\n",
      "[CV 1/5; 4/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   2.3s\n",
      "[CV 2/5; 4/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 4/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   3.1s\n",
      "[CV 3/5; 4/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 4/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   2.7s\n",
      "[CV 4/5; 4/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   1.8s\n",
      "[CV 5/5; 4/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 4/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.611) total time=   2.3s\n",
      "[CV 1/5; 5/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   2.3s\n",
      "[CV 2/5; 5/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 5/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   2.6s\n",
      "[CV 3/5; 5/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 5/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.444) total time=   2.9s\n",
      "[CV 4/5; 5/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 5/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.722) total time=   2.0s\n",
      "[CV 5/5; 5/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 5/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.611) total time=   2.9s\n",
      "[CV 1/5; 6/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 6/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.556) total time=   1.9s\n",
      "[CV 2/5; 6/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 6/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   2.6s\n",
      "[CV 3/5; 6/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 6/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.722) total time=   2.9s\n",
      "[CV 4/5; 6/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.444) total time=   2.3s\n",
      "[CV 5/5; 6/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 6/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   2.7s\n",
      "[CV 1/5; 7/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 7/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.611) total time=   2.5s\n",
      "[CV 2/5; 7/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 7/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.556) total time=   3.0s\n",
      "[CV 3/5; 7/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 7/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.611) total time=   3.5s\n",
      "[CV 4/5; 7/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 7/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.556) total time=   2.4s\n",
      "[CV 5/5; 7/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 7/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.556) total time=   3.1s\n",
      "[CV 1/5; 8/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 8/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   1.9s\n",
      "[CV 2/5; 8/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 8/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   2.5s\n",
      "[CV 3/5; 8/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 8/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   2.4s\n",
      "[CV 4/5; 8/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 8/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.611) total time=   1.8s\n",
      "[CV 5/5; 8/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 8/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.611) total time=   2.6s\n",
      "[CV 1/5; 9/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.611) total time=   3.4s\n",
      "[CV 2/5; 9/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 9/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.556) total time=   2.9s\n",
      "[CV 3/5; 9/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 9/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   2.8s\n",
      "[CV 4/5; 9/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   2.8s\n",
      "[CV 5/5; 9/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 9/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   3.5s\n",
      "[CV 1/5; 10/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 10/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.611) total time=   5.2s\n",
      "[CV 2/5; 10/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 10/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.556) total time=   4.3s\n",
      "[CV 3/5; 10/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 10/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.722) total time=   4.5s\n",
      "[CV 4/5; 10/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 10/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   5.8s\n",
      "[CV 5/5; 10/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 10/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.611) total time=   5.1s\n",
      "[CV 1/5; 11/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   1.8s\n",
      "[CV 2/5; 11/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 11/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   2.2s\n",
      "[CV 3/5; 11/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 11/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.444) total time=   2.2s\n",
      "[CV 4/5; 11/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 11/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.722) total time=   2.4s\n",
      "[CV 5/5; 11/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 11/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   2.8s\n",
      "[CV 1/5; 12/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 12/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.611) total time=   2.5s\n",
      "[CV 2/5; 12/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 12/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   3.1s\n",
      "[CV 3/5; 12/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 12/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.722) total time=   2.3s\n",
      "[CV 4/5; 12/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 12/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.556) total time=   2.5s\n",
      "[CV 5/5; 12/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 12/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   2.8s\n",
      "[CV 1/5; 13/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 13/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.611) total time=   3.2s\n",
      "[CV 2/5; 13/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 13/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.556) total time=   2.8s\n",
      "[CV 3/5; 13/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 13/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.556) total time=   3.6s\n",
      "[CV 4/5; 13/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 13/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.556) total time=   3.2s\n",
      "[CV 5/5; 13/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 13/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   3.2s\n",
      "[CV 1/5; 14/20] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 14/20] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   1.8s\n",
      "[CV 2/5; 14/20] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 14/20] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   2.2s\n",
      "[CV 3/5; 14/20] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 14/20] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   2.2s\n",
      "[CV 4/5; 14/20] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 14/20] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   1.5s\n",
      "[CV 5/5; 14/20] START clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 14/20] END clf=RandomForestClassifier(random_state=69), clf__criterion=entropy, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   2.1s\n",
      "[CV 1/5; 15/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 15/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.611) total time=   1.7s\n",
      "[CV 2/5; 15/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 15/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   1.9s\n",
      "[CV 3/5; 15/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 15/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   2.1s\n",
      "[CV 4/5; 15/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 15/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   1.7s\n",
      "[CV 5/5; 15/20] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 15/20] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   1.9s\n",
      "[CV 1/5; 16/20] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 16/20] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   1.5s\n",
      "[CV 2/5; 16/20] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 16/20] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   2.7s\n",
      "[CV 3/5; 16/20] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 16/20] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.389) total time=   2.2s\n",
      "[CV 4/5; 16/20] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 16/20] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   2.0s\n",
      "[CV 5/5; 16/20] START clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 16/20] END clf=RandomForestClassifier(random_state=69), clf__criterion=gini, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   2.3s\n",
      "[CV 1/5; 17/20] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 17/20] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.986, test=0.556) total time=   2.2s\n",
      "[CV 2/5; 17/20] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 17/20] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.986, test=0.500) total time=   2.4s\n",
      "[CV 3/5; 17/20] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 17/20] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.986, test=0.556) total time=   2.5s\n",
      "[CV 4/5; 17/20] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 17/20] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.611) total time=   1.8s\n",
      "[CV 5/5; 17/20] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 17/20] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   2.7s\n",
      "[CV 1/5; 18/20] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 18/20] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.973, test=0.556) total time=   1.5s\n",
      "[CV 2/5; 18/20] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 18/20] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.986, test=0.500) total time=   1.9s\n",
      "[CV 3/5; 18/20] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 18/20] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.986, test=0.556) total time=   1.9s\n",
      "[CV 4/5; 18/20] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 18/20] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   1.9s\n",
      "[CV 5/5; 18/20] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 18/20] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.667) total time=   2.2s\n",
      "[CV 1/5; 19/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 19/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.556) total time=   2.5s\n",
      "[CV 2/5; 19/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 19/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.556) total time=   3.0s\n",
      "[CV 3/5; 19/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 19/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.556) total time=   3.9s\n",
      "[CV 4/5; 19/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 19/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.556) total time=   3.4s\n",
      "[CV 5/5; 19/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 19/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.667) total time=   3.3s\n",
      "[CV 1/5; 20/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 20/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.611) total time=   1.8s\n",
      "[CV 2/5; 20/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 20/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   1.9s\n",
      "[CV 3/5; 20/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 20/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   2.0s\n",
      "[CV 4/5; 20/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 20/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.611) total time=   1.9s\n",
      "[CV 5/5; 20/20] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 20/20] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=20, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.611) total time=   3.0s\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 7\n",
      "n_resources: 279\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[CV 1/5; 1/7] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/7] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.982, test=0.636) total time=   6.1s\n",
      "[CV 2/5; 1/7] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/7] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.969, test=0.655) total time=   6.1s\n",
      "[CV 3/5; 1/7] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/7] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.973, test=0.564) total time=   6.1s\n",
      "[CV 4/5; 1/7] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/7] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.987, test=0.564) total time=   6.8s\n",
      "[CV 5/5; 1/7] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/7] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.987, test=0.582) total time=   6.3s\n",
      "[CV 1/5; 2/7] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/7] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.527) total time=   7.9s\n",
      "[CV 2/5; 2/7] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/7] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.600) total time=   7.9s\n",
      "[CV 3/5; 2/7] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/7] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.582) total time=   8.6s\n",
      "[CV 4/5; 2/7] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 2/7] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.545) total time=   9.3s\n",
      "[CV 5/5; 2/7] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/7] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=40, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.545) total time=  13.5s\n",
      "[CV 1/5; 3/7] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/7] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.564) total time=   9.3s\n",
      "[CV 2/5; 3/7] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/7] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.636) total time=   9.9s\n",
      "[CV 3/5; 3/7] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/7] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.582) total time=  14.0s\n",
      "[CV 4/5; 3/7] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/7] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.582) total time=  11.2s\n",
      "[CV 5/5; 3/7] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/7] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.527) total time=  11.0s\n",
      "[CV 1/5; 4/7] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/7] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.991, test=0.600) total time=  10.7s\n",
      "[CV 2/5; 4/7] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/7] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.996, test=0.636) total time=   9.1s\n",
      "[CV 3/5; 4/7] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/7] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.996, test=0.582) total time=  10.2s\n",
      "[CV 4/5; 4/7] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/7] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.996, test=0.582) total time=  10.5s\n",
      "[CV 5/5; 4/7] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 4/7] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.545) total time=  11.0s\n",
      "[CV 1/5; 5/7] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/7] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.582) total time=   7.8s\n",
      "[CV 2/5; 5/7] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/7] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.636) total time=   8.1s\n",
      "[CV 3/5; 5/7] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/7] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.600) total time=   9.4s\n",
      "[CV 4/5; 5/7] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 5/7] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.564) total time=   8.9s\n",
      "[CV 5/5; 5/7] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/7] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.491) total time=   8.7s\n",
      "[CV 1/5; 6/7] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/7] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.564) total time=  14.9s\n",
      "[CV 2/5; 6/7] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/7] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.618) total time=  14.4s\n",
      "[CV 3/5; 6/7] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/7] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.564) total time=  16.4s\n",
      "[CV 4/5; 6/7] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/7] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.545) total time=  17.4s\n",
      "[CV 5/5; 6/7] START clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 6/7] END clf=LogisticRegression(random_state=420), clf__C=10, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.509) total time=  17.1s\n",
      "[CV 1/5; 7/7] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 7/7] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.582) total time=   7.5s\n",
      "[CV 2/5; 7/7] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 7/7] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.618) total time=   7.8s\n",
      "[CV 3/5; 7/7] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 7/7] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.600) total time=   9.0s\n",
      "[CV 4/5; 7/7] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 7/7] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.582) total time=   8.8s\n",
      "[CV 5/5; 7/7] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 7/7] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.509) total time=   9.6s\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 837\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5; 1/3] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/3] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.999, test=0.653) total time=  24.7s\n",
      "[CV 2/5; 1/3] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/3] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.629) total time=  26.0s\n",
      "[CV 3/5; 1/3] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/3] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.629) total time=  25.7s\n",
      "[CV 4/5; 1/3] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/3] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.999, test=0.671) total time=  29.4s\n",
      "[CV 5/5; 1/3] START clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/3] END clf=LogisticRegression(random_state=420), clf__C=1, feature selection__percentile=60, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.999, test=0.659) total time=  23.9s\n",
      "[CV 1/5; 2/3] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/3] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.993, test=0.665) total time=  31.6s\n",
      "[CV 2/5; 2/3] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/3] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.994, test=0.635) total time=  29.3s\n",
      "[CV 3/5; 2/3] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/3] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.994, test=0.635) total time=  39.8s\n",
      "[CV 4/5; 2/3] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 2/3] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.996, test=0.695) total time= 1.0min\n",
      "[CV 5/5; 2/3] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/3] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.994, test=0.653) total time= 1.2min\n",
      "[CV 1/5; 3/3] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/3] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.982, test=0.707) total time=  33.6s\n",
      "[CV 2/5; 3/3] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/3] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.984, test=0.635) total time=  31.2s\n",
      "[CV 3/5; 3/3] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/3] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.984, test=0.659) total time=  32.5s\n",
      "[CV 4/5; 3/3] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/3] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.984, test=0.695) total time=  31.3s\n",
      "[CV 5/5; 3/3] START clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/3] END clf=LogisticRegression(random_state=420), clf__C=0.1, feature selection__percentile=80, feature selection__score_func=<function f_classif at 0x000001C56F3F41F0>, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.985, test=0.689) total time=  33.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waldo\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HalvingGridSearchCV(estimator=Pipeline(steps=[('preprocessing',\n",
       "                                               ColumnTransformer(transformers=[('bow',\n",
       "                                                                                CountVectorizer(ngram_range=(1,\n",
       "                                                                                                             2),\n",
       "                                                                                                tokenizer=<__main__.StemmerTokenizer object at 0x000001C571AB06D0>),\n",
       "                                                                                'history_text'),\n",
       "                                                                               ('minmaxscaler',\n",
       "                                                                                MinMaxScaler(),\n",
       "                                                                                ['intelligence_score',\n",
       "                                                                                 'strength_score',\n",
       "                                                                                 'speed_score',\n",
       "                                                                                 'durability_score',\n",
       "                                                                                 'power_score',\n",
       "                                                                                 'combat_score'])...\n",
       "                                 'feature selection__score_func': [<function f_classif at 0x000001C56F3F41F0>],\n",
       "                                 'preprocessing__bow__ngram_range': [(1, 1),\n",
       "                                                                     (1, 2),\n",
       "                                                                     (1, 3)]},\n",
       "                                {'clf': [RandomForestClassifier(random_state=69)],\n",
       "                                 'clf__criterion': ['gini', 'entropy'],\n",
       "                                 'feature selection__percentile': [20, 40, 60,\n",
       "                                                                   80],\n",
       "                                 'feature selection__score_func': [<function f_classif at 0x000001C56F3F41F0>],\n",
       "                                 'preprocessing__bow__ngram_range': [(1, 1),\n",
       "                                                                     (1, 2),\n",
       "                                                                     (1, 3)]}],\n",
       "                    scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grid = search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.66      0.54      0.59       142\n",
      "        Good       0.73      0.89      0.80       246\n",
      "     Neutral       0.00      0.00      0.00        37\n",
      "\n",
      "    accuracy                           0.70       425\n",
      "   macro avg       0.46      0.48      0.47       425\n",
      "weighted avg       0.64      0.70      0.66       425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados mejoran significativamente, ahora se obtienen mejores resultados clasificando personajes malos. A칰n se tiene malos resultados para personajes neutrales, pero esto puede ser explicado por el bajo soporte de esta clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00042-1dc5444c-59e9-4d79-93fb-3c545fe3b086",
    "deepnote_cell_type": "markdown",
    "id": "OmQUw2aZ_6z2"
   },
   "source": [
    "## 1.4 Predicci칩n del datos sin etiquetado  [0.5 puntos]\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://pbs.twimg.com/media/DolotxUUYAAbg7f.jpg\" width=\"350\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00043-bdf593d2-92b5-4d74-869a-8c9541a6e572",
    "deepnote_cell_type": "markdown",
    "id": "Cj0ERBgTBFWN"
   },
   "source": [
    "LLego el momento de predecir \n",
    "`Vergil`, `Gorilla Girl` y `Batcow`\n",
    "\n",
    "\n",
    "**Nota:** Recuerde que pueden existir campos vacios en `history_text`, por lo que se les recomienda borrar los nan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00035-1e9b40e0-20dc-4ed1-81ca-b7f8f9679771",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": "00035-1ec91701-af2f-4571-9067-f82dbc6f2989",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_comics_no_label = pd.read_csv('comics_no_label.csv').dropna(subset=['history_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>real_name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>overall_score</th>\n",
       "      <th>history_text</th>\n",
       "      <th>powers_text</th>\n",
       "      <th>intelligence_score</th>\n",
       "      <th>strength_score</th>\n",
       "      <th>speed_score</th>\n",
       "      <th>...</th>\n",
       "      <th>has_flight</th>\n",
       "      <th>has_accelerated_healing</th>\n",
       "      <th>has_weapons_master</th>\n",
       "      <th>has_intelligence</th>\n",
       "      <th>has_reflexes</th>\n",
       "      <th>has_super_speed</th>\n",
       "      <th>has_durability</th>\n",
       "      <th>has_stamina</th>\n",
       "      <th>has_agility</th>\n",
       "      <th>has_super_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>514A (Gotham)</td>\n",
       "      <td>Bruce Wayne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>He was one of the many prisoners of Indian Hil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>A'dal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>As with most of the naaru, little is known of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>Agent Zero (FOX)</td>\n",
       "      <td>David North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>During mid-late 1973, Zero was a member of Tea...</td>\n",
       "      <td>Zero can absorb kinetic energy to further incr...</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>Ajax (FOX)</td>\n",
       "      <td>Francis</td>\n",
       "      <td>Francis Freeman</td>\n",
       "      <td>7</td>\n",
       "      <td>Ajax (born Francis Freeman) was a human who ga...</td>\n",
       "      <td>Ajax has claimed that the procedure to obtain ...</td>\n",
       "      <td>85</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46</td>\n",
       "      <td>A.M.A.Z.O. (CW)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>The Anti Meta-human Adaptive Zootomic Organism...</td>\n",
       "      <td>With its metallic body, it easily overpowered ...</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1368</td>\n",
       "      <td>Vergil</td>\n",
       "      <td>Vergil Sparda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>Vergil, later also known as Nelo Angelo, is on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1396</td>\n",
       "      <td>Wendigo</td>\n",
       "      <td>Wendigo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>The Wendigo are the result of an ancient curse...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1431</td>\n",
       "      <td>XS (CW)</td>\n",
       "      <td>Nora West-Allen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>According to Eobard Thawne, the daughter of Ba...</td>\n",
       "      <td>Nora possesses a natural connection to the Spe...</td>\n",
       "      <td>90</td>\n",
       "      <td>55</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1440</td>\n",
       "      <td>Yondu (MCU)</td>\n",
       "      <td>Yondu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>Yondu Udonta was a Centaurian, leader of a key...</td>\n",
       "      <td>Yondu Udonta was a member of the Centaurians, ...</td>\n",
       "      <td>85</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>122</td>\n",
       "      <td>Batcow</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>Bat-Cow was originally a cow that was found by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows 칑 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0              name        real_name        full_name  \\\n",
       "0            1     514A (Gotham)      Bruce Wayne              NaN   \n",
       "2           17             A'dal              NaN              NaN   \n",
       "3           27  Agent Zero (FOX)      David North              NaN   \n",
       "4           31        Ajax (FOX)          Francis  Francis Freeman   \n",
       "6           46   A.M.A.Z.O. (CW)              NaN              NaN   \n",
       "..         ...               ...              ...              ...   \n",
       "78        1368            Vergil    Vergil Sparda              NaN   \n",
       "80        1396           Wendigo          Wendigo              NaN   \n",
       "81        1431           XS (CW)  Nora West-Allen              NaN   \n",
       "82        1440       Yondu (MCU)            Yondu              NaN   \n",
       "83         122            Batcow             None             None   \n",
       "\n",
       "   overall_score                                       history_text  \\\n",
       "0             10  He was one of the many prisoners of Indian Hil...   \n",
       "2              7  As with most of the naaru, little is known of ...   \n",
       "3              6  During mid-late 1973, Zero was a member of Tea...   \n",
       "4              7  Ajax (born Francis Freeman) was a human who ga...   \n",
       "6             22  The Anti Meta-human Adaptive Zootomic Organism...   \n",
       "..           ...                                                ...   \n",
       "78            16  Vergil, later also known as Nelo Angelo, is on...   \n",
       "80             6  The Wendigo are the result of an ancient curse...   \n",
       "81            19  According to Eobard Thawne, the daughter of Ba...   \n",
       "82             7  Yondu Udonta was a Centaurian, leader of a key...   \n",
       "83             3  Bat-Cow was originally a cow that was found by...   \n",
       "\n",
       "                                          powers_text  intelligence_score  \\\n",
       "0                                                 NaN                 100   \n",
       "2                                                 NaN                  85   \n",
       "3   Zero can absorb kinetic energy to further incr...                  90   \n",
       "4   Ajax has claimed that the procedure to obtain ...                  85   \n",
       "6   With its metallic body, it easily overpowered ...                  90   \n",
       "..                                                ...                 ...   \n",
       "78                                                NaN                  90   \n",
       "80                                                NaN                  65   \n",
       "81  Nora possesses a natural connection to the Spe...                  90   \n",
       "82  Yondu Udonta was a member of the Centaurians, ...                  85   \n",
       "83                                                NaN                  70   \n",
       "\n",
       "    strength_score  speed_score  ...  has_flight  has_accelerated_healing  \\\n",
       "0               20           30  ...         0.0                      0.0   \n",
       "2               30           70  ...         0.0                      0.0   \n",
       "3               10           25  ...         0.0                      0.0   \n",
       "4               25           45  ...         0.0                      0.0   \n",
       "6              100          100  ...         1.0                      0.0   \n",
       "..             ...          ...  ...         ...                      ...   \n",
       "78              75           95  ...         0.0                      1.0   \n",
       "80              80           75  ...         0.0                      0.0   \n",
       "81              55          100  ...         0.0                      1.0   \n",
       "82              25           40  ...         0.0                      0.0   \n",
       "83              10           25  ...         0.0                      0.0   \n",
       "\n",
       "    has_weapons_master has_intelligence has_reflexes has_super_speed  \\\n",
       "0                  0.0              0.0          1.0             0.0   \n",
       "2                  0.0              0.0          0.0             0.0   \n",
       "3                  0.0              0.0          1.0             0.0   \n",
       "4                  1.0              1.0          1.0             0.0   \n",
       "6                  1.0              0.0          0.0             0.0   \n",
       "..                 ...              ...          ...             ...   \n",
       "78                 1.0              1.0          1.0             1.0   \n",
       "80                 0.0              0.0          0.0             0.0   \n",
       "81                 0.0              0.0          1.0             1.0   \n",
       "82                 1.0              0.0          0.0             0.0   \n",
       "83                 0.0              0.0          0.0             0.0   \n",
       "\n",
       "   has_durability has_stamina has_agility  has_super_strength  \n",
       "0             1.0         0.0         0.0                 1.0  \n",
       "2             0.0         0.0         0.0                 0.0  \n",
       "3             0.0         0.0         1.0                 0.0  \n",
       "4             1.0         0.0         0.0                 1.0  \n",
       "6             0.0         0.0         0.0                 0.0  \n",
       "..            ...         ...         ...                 ...  \n",
       "78            1.0         1.0         1.0                 1.0  \n",
       "80            0.0         0.0         0.0                 1.0  \n",
       "81            1.0         1.0         1.0                 0.0  \n",
       "82            0.0         0.0         0.0                 0.0  \n",
       "83            0.0         0.0         0.0                 0.0  \n",
       "\n",
       "[76 rows x 82 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comics_no_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Good'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.predict(df_comics_no_label[df_comics_no_label['name'] == 'Vergil'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Good'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.predict(df_comics_no_label[df_comics_no_label['name'] == 'Gorilla Girl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Good', 'Good'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.predict(df_comics_no_label[df_comics_no_label['name'] == 'Batcow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00045-bf830861-7edd-434b-93f5-af4b0404ce83",
    "deepnote_cell_type": "markdown",
    "id": "Rg4ZMq8ezAH6"
   },
   "source": [
    "# Conclusi칩n\n",
    "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana y que **los d칤as de atraso no se pueden utilizar para entregas de lab, solo para tareas**. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/images/fb5bf7cc5a4acb91b4177672886a88ba/tenor.gif?itemid=5591338\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LCOUC4jss148",
    "GtG74Cphq56p"
   ],
   "name": "Laboratorio4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "038fcdf2-d87a-4a74-89c6-f5afff22afb6",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contenidos",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
